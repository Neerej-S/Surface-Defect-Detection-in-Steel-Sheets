{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\Defect Dectetion\\\\dataset_metal_surface\\\\test'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     18\u001b[39m transform = transforms.Compose([\n\u001b[32m     19\u001b[39m     transforms.Resize((\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)),\n\u001b[32m     20\u001b[39m     transforms.ToTensor(),\n\u001b[32m     21\u001b[39m     transforms.Normalize([\u001b[32m0.5\u001b[39m], [\u001b[32m0.5\u001b[39m])\n\u001b[32m     22\u001b[39m ])\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Load test dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m test_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mE:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDefect Dectetion\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdataset_metal_surface\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m16\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S NEEREJ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S NEEREJ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S NEEREJ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S NEEREJ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'E:\\\\Defect Dectetion\\\\dataset_metal_surface\\\\test'"
     ]
    }
   ],
   "source": [
    "## test.py\n",
    "import torch\n",
    "import torch.nn as nnE\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data preprocessing (MUST match training preprocessing)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = datasets.ImageFolder(r\"C:\\Users\\S NEEREJ\\Desktop\\Defect Dectetion\\dataset_metal_surface\\test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load trained model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 6)  # 6 classes for defect detection\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\S NEEREJ\\Desktop\\Defect Dectetion\\best_model.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Class labels\n",
    "CLASS_LABELS = [\"Crazing\", \"Inclusion\", \"Patches\", \"Pitted\", \"Rolled\", \"Scratches\"]\n",
    "\n",
    "# Grad-CAM implementation\n",
    "def grad_cam(model, image):\n",
    "    model.eval()\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    features, gradients = [], []\n",
    "    def forward_hook(module, input, output):\n",
    "        features.append(output)\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        gradients.append(grad_out[0])\n",
    "    \n",
    "    target_layer = model.layer4[-1]\n",
    "    target_layer.register_forward_hook(forward_hook)\n",
    "    target_layer.register_backward_hook(backward_hook)\n",
    "    \n",
    "    output = model(image)\n",
    "    class_idx = torch.argmax(output, dim=1).item()\n",
    "    model.zero_grad()\n",
    "    output[0, class_idx].backward()\n",
    "    \n",
    "    grads = gradients[0].mean(dim=[2, 3], keepdim=True)\n",
    "    cam = torch.relu((features[0] * grads).sum(dim=1)).squeeze()\n",
    "    cam = F.interpolate(cam.unsqueeze(0).unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False)\n",
    "    cam = cam.squeeze().cpu().detach().numpy()\n",
    "    cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "    \n",
    "    return cam, class_idx\n",
    "\n",
    "# Masking function\n",
    "def apply_mask(heatmap, threshold=0.6):\n",
    "    return np.where(heatmap >= threshold, 255, 0).astype(np.uint8)\n",
    "\n",
    "# Bounding box function\n",
    "def get_bounding_box(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    return cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "\n",
    "# Heatmap overlay function\n",
    "def overlay_heatmap(image, heatmap):\n",
    "    image = np.array(image)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    return cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "# Inference function\n",
    "def infer_and_visualize(model, image_path):\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image_pil).to(device)\n",
    "    heatmap, class_idx = grad_cam(model, image_tensor)\n",
    "    defect_name = CLASS_LABELS[class_idx]\n",
    "    \n",
    "    mask = apply_mask(heatmap)\n",
    "    bbox = get_bounding_box(mask)\n",
    "    image_cv = np.array(image_pil)\n",
    "    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if bbox:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(image_cv, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image_cv, defect_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)\n",
    "    overlay = overlay_heatmap(image_pil, heatmap)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_pil)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f\"Grad-CAM Heatmap: {defect_name}\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(image_cv)\n",
    "    plt.title(\"Defect Detection with Bounding Box\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Prediction: {defect_name}\")\n",
    "    if bbox:\n",
    "        print(f\"Bounding Box: x={bbox[0]}, y={bbox[1]}, width={bbox[2]}, height={bbox[3]}\")\n",
    "    else:\n",
    "        print(\"No significant defect detected.\")\n",
    "\n",
    "# Testing function\n",
    "def test(model, test_loader):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "# Run testing\n",
    "test(model, test_loader)\n",
    "\n",
    "# Example inference\n",
    "image_path =r\"C:\\Users\\S NEEREJ\\Desktop\\Defect Dectetion\\dataset_metal_surface\\test\\Pitted\\PS_101.bmp\"\n",
    "infer_and_visualize(model, image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
